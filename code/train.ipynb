{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os.path as osp\n",
    "import csv\n",
    "import utils as ut\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch_geometric\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import json \n",
    "import tqdm\n",
    "\n",
    "from detanet_model import *\n",
    "from preprocess_data import load_polarizabilities, save_dataset_to_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DynDetaNet(\n",
       "  (Embedding): Embedding(\n",
       "    (act): Swish()\n",
       "    (elec_emb): Linear(in_features=16, out_features=128, bias=False)\n",
       "    (nuclare_emb): Embedding(35, 128)\n",
       "    (ls): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (Radial): Radial_Basis(\n",
       "    (radial): Bessel_Function()\n",
       "  )\n",
       "  (FreqEmbedding): FrequencyEmbedding(\n",
       "    (linear1): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (linear2): Linear(in_features=16, out_features=128, bias=True)\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tout): Equivariant_Multilayer(\n",
       "    (e_mlp): Sequential(\n",
       "      (0): Linear(128x1o+128x2e+128x3o -> 128x2e | 16384 weights)\n",
       "      (1): Activation [ ] (128x2e -> 128x2e)\n",
       "      (2): Linear(128x2e -> 2x2e | 256 weights)\n",
       "    )\n",
       "  )\n",
       "  (sout): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Swish()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DynDetaNet(num_features=128,\n",
    "                    act='swish',\n",
    "                    maxl=3,\n",
    "                    num_block=3,\n",
    "                    radial_type='trainable_bessel',\n",
    "                    num_radial=32,\n",
    "                    attention_head=8,\n",
    "                    rc=5.0,\n",
    "                    dropout=0.0,\n",
    "                    use_cutoff=False,\n",
    "                    max_atomic_number=34,\n",
    "                    atom_ref=None,\n",
    "                    scale=1.0,\n",
    "                    scalar_outsize=4, # 2,#4, \n",
    "                    irreps_out='2x2e', #'2e',# '2e+2e',\n",
    "                    summation=True,\n",
    "                    norm=False,\n",
    "                    out_type='complex_2_tensor', # '2_tensor',\n",
    "                    grad_type=None,\n",
    "                    device=device)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sym3x3_to_values(mat3x3: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Given a 3x3 symmetric matrix (as a Tensor),\n",
    "    extract the 6 unique elements in the order:\n",
    "      [xx, xy, xz, yy, yz, zz]\n",
    "    Returns a Tensor of shape [6].\n",
    "    \"\"\"\n",
    "    # mat3x3 shape is [3, 3]\n",
    "    # Ensure it's 2D\n",
    "    xx = mat3x3[0, 0]\n",
    "    xy = mat3x3[0, 1]\n",
    "    xz = mat3x3[0, 2]\n",
    "    yy = mat3x3[1, 1]\n",
    "    yz = mat3x3[1, 2]\n",
    "    zz = mat3x3[2, 2]\n",
    "\n",
    "    return torch.stack([xx, xy, xz, yy, yz, zz])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(y=[12], pos=[33, 3], z=[33], freq=1.5498024225234985)\n"
     ]
    }
   ],
   "source": [
    "notebook_dir = Path(os.getcwd())\n",
    "parent_dir = os.path.dirname(notebook_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "\n",
    "csv_path = data_dir + \"/ee_polarizabilities.csv\"\n",
    "\n",
    "dataset = []\n",
    "with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Read the header to identify column indices\n",
    "    header = next(csv_reader)\n",
    "    smiles_idx = header.index(\"smiles\")\n",
    "    frequency_idx = header.index(\"frequency\")\n",
    "    matrix_real_idx = header.index(\"matrix_real\")\n",
    "    matrix_imag_idx = header.index(\"matrix_imag\")\n",
    "    \n",
    "    # Read each row\n",
    "    for row in csv_reader:\n",
    "        smiles = row[smiles_idx]\n",
    "        freq = row[frequency_idx]\n",
    "        matrix_real_str = row[matrix_real_idx]\n",
    "        matrix_imag_str = row[matrix_imag_idx]\n",
    "        try:\n",
    "            freq_val = float(freq)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        # Parse JSON for real matrix\n",
    "        try:\n",
    "            real_3x3 = json.loads(matrix_real_str)  # shape expected [3,3]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse real part of matrix\")\n",
    "            continue\n",
    "\n",
    "        # Parse JSON for imaginary matrix\n",
    "        try:\n",
    "            imag_3x3 = json.loads(matrix_imag_str)\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse imaginary part of matrix\")\n",
    "            continue\n",
    "\n",
    "        # Convert to torch Tensors (shape [3,3])\n",
    "        real_mat = torch.tensor(real_3x3, dtype=torch.float32)\n",
    "        imag_mat = torch.tensor(imag_3x3, dtype=torch.float32)\n",
    "\n",
    "        # Each is a 3x3 symmetric matrix; extract the 6 unique elements\n",
    "        real_values = sym3x3_to_values(real_mat)  # shape [6]\n",
    "        imag_values = sym3x3_to_values(imag_mat)  # shape [6]\n",
    "\n",
    "        # Concatenate => 12 elements total\n",
    "        # first 6 = real, last 6 = imaginary\n",
    "        y = torch.cat([real_values, imag_values], dim=0)  # shape [12]\n",
    "\n",
    "        # Convert SMILES to molecular graph\n",
    "        graph_data = ut.smiles_to_graph(smiles)\n",
    "        if graph_data is None:\n",
    "            continue  # Skip invalid molecules\n",
    "        \n",
    "        z, pos = graph_data\n",
    "        \n",
    "        # Create a PyTorch Geometric Data object\n",
    "        data_entry = Data(\n",
    "            pos=pos.to(torch.float32),    # Atomic positions\n",
    "            z=torch.LongTensor(z),        # Atomic numbers\n",
    "            freq=torch.tensor(float(freq), dtype=torch.float32),\n",
    "            y=y,  # Polarizability tensor (target)\n",
    "        )\n",
    "        \n",
    "        dataset.append(data_entry)\n",
    "        if len(dataset) == 143:\n",
    "            break\n",
    "\n",
    "print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datasets=[]\n",
    "val_datasets=[]\n",
    "for i in range(len(dataset)):\n",
    "    if i%10==0:\n",
    "        val_datasets.append(dataset[i])\n",
    "    else:\n",
    "        train_datasets.append(dataset[i])\n",
    "        \n",
    "len(train_datasets),len(val_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Using torch_Geometric.dataloader.DataLoader Converts a dataset into a batch of 64 molecules of training data.'''\n",
    "batches=16\n",
    "trainloader=DataLoader(train_datasets,batch_size=batches,shuffle=True)\n",
    "valloader=DataLoader(val_datasets,batch_size=batches,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Next, define the trainer and the parameters used for training.'''\n",
    "class Trainer:\n",
    "    def __init__(self,model,train_loader,val_loader=None,loss_function=l2loss,device=torch.device(device),\n",
    "                 optimizer='Adam_amsgrad',lr=5e-4,weight_decay=0):\n",
    "        self.opt_type=optimizer\n",
    "        self.device=device\n",
    "        self.model=model\n",
    "        self.train_data=train_loader\n",
    "        self.val_data=val_loader\n",
    "        self.device=device\n",
    "        self.opts={'AdamW':torch.optim.AdamW(self.model.parameters(),lr=lr,amsgrad=False,weight_decay=weight_decay),\n",
    "              'AdamW_amsgrad':torch.optim.AdamW(self.model.parameters(),lr=lr,amsgrad=True,weight_decay=weight_decay),\n",
    "              'Adam':torch.optim.Adam(self.model.parameters(),lr=lr,amsgrad=False,weight_decay=weight_decay),\n",
    "              'Adam_amsgrad':torch.optim.Adam(self.model.parameters(),lr=lr,amsgrad=True,weight_decay=weight_decay),\n",
    "              'Adadelta':torch.optim.Adadelta(self.model.parameters(),lr=lr,weight_decay=weight_decay),\n",
    "              'RMSprop':torch.optim.RMSprop(self.model.parameters(),lr=lr,weight_decay=weight_decay),\n",
    "              'SGD':torch.optim.SGD(self.model.parameters(),lr=lr,weight_decay=weight_decay)\n",
    "        }\n",
    "        self.optimizer=self.opts[self.opt_type]\n",
    "        self.loss_function=loss_function\n",
    "        self.step=-1\n",
    "    def train(self,num_train,targ,stop_loss=1e-8, val_per_train=50, print_per_epoch=10):\n",
    "        self.model.train()\n",
    "        len_train=len(self.train_data)\n",
    "        for i in range(num_train):\n",
    "            val_datas=iter(self.val_data)\n",
    "            for j,batch in enumerate(self.train_data):\n",
    "                self.step=self.step+1\n",
    "                torch.cuda.empty_cache()\n",
    "                self.optimizer.zero_grad()\n",
    "                out = self.model(pos=batch.pos.to(self.device), z=batch.z.to(self.device), freq=batch.freq.to(self.device),\n",
    "                                 batch=batch.batch.to(self.device))\n",
    "                #no pooling necessary, happens inside of model, graph_out = global_mean_pool(out.to(self.device), batch.batch.to(self.device))  # Shape: [batch_size, d]\n",
    "                # print(\"out.shape\", out.shape)\n",
    "                # outs_re, outs_im = torch.split(out, 6, dim=-1)\n",
    "                # print(\"outs_re\", outs_re.shape)\n",
    "                # print(\"outs_im\", outs_im.shape)\n",
    "\n",
    "                target = batch[targ].to(self.device)\n",
    "\n",
    "                # print(\"target\" , target.shape)\n",
    "                loss = self.loss_function(out.reshape(target.shape),target)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                if (self.step%val_per_train==0) and (self.val_data is not None):\n",
    "                    val_batch = next(val_datas)\n",
    "                    val_target=val_batch[targ].to(self.device).reshape(-1)\n",
    "\n",
    "                    val_out = self.model(pos=val_batch.pos.to(self.device), z=val_batch.z.to(self.device), freq=batch.freq.to(self.device), batch=val_batch.batch.to(self.device))\n",
    "\n",
    "                    # Ensure the shapes match\n",
    "                    val_loss = self.loss_function(val_out.reshape(val_target.shape), val_target.to(self.device)).item()\n",
    "                    val_mae = l1loss(val_out.reshape(val_target.shape), val_target.to(self.device)).item()\n",
    "                    val_R2 = R2(val_out.reshape(val_target.shape), val_target.to(self.device)).item()\n",
    "\n",
    "                    if self.step % print_per_epoch==0:\n",
    "                        logging.info('Epoch[{}/{}],loss:{:.8f},val_loss:{:.8f},val_mae:{:.8f},val_R2:{:.8f}'\n",
    "                              .format(self.step,num_train*len_train,loss.item(),val_loss,val_mae,val_R2))\n",
    "\n",
    "                    assert (loss > stop_loss) or (val_loss > stop_loss),'Training and prediction Loss is less' \\\n",
    "                                                                        ' than cut-off Loss, so training stops'\n",
    "                elif (self.step % print_per_epoch == 0) and (self.step%val_per_train!=0):\n",
    "                    logging.info('Epoch[{}/{}],loss:{:.8f}'.format(self.step,num_train*len_train, loss.item()))\n",
    "                    \n",
    "    def load_state_and_optimizer(self,state_path=None,optimizer_path=None):\n",
    "        if state_path is not None:\n",
    "            state_dict=torch.load(state_path)\n",
    "            self.model.load_state_dict(state_dict)\n",
    "        if optimizer_path is not None:\n",
    "            self.optimizer=torch.load(optimizer_path)\n",
    "\n",
    "    def save_param(self,path):\n",
    "        torch.save(self.model.state_dict(),path)\n",
    "\n",
    "    def save_model(self,path):\n",
    "        torch.save(self.model, path)\n",
    "\n",
    "    def save_opt(self,path):\n",
    "        torch.save(self.optimizer,path)\n",
    "\n",
    "    def params(self):\n",
    "        return self.model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device) \n",
    "'''Finally, using the trainer, training 20 times from a 5e-4 learning rate'''\n",
    "trainer=Trainer(model,train_loader=trainloader,val_loader=valloader,loss_function=l2loss,lr=5e-4,weight_decay=0,optimizer='AdamW')\n",
    "trainer.train(num_train=25,targ='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'trained_param/ee_polarizabilities.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
