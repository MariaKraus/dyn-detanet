{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import csv\n",
    "import util as ut\n",
    "import pandas as pd\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRU, Linear, ReLU, Sequential\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.datasets import QM9\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import NNConv, Set2Set\n",
    "from torch_geometric.utils import remove_self_loops\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "import torch_geometric\n",
    "import logging\n",
    "\n",
    "from pathlib import Path\n",
    "import trainer\n",
    "import json \n",
    "\n",
    "from detanet_model import *\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 60\n",
    "lr=5e-4\n",
    "num_freqs=61\n",
    "\n",
    "high_spec_cutoff = 0.1\n",
    "low_fraction = 0.006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "data_dir = os.path.join(parent_dir, 'data')\n",
    "csv_path = data_dir + \"/ee_polarizabilities_qm9s.csv\"\n",
    "\n",
    "dataset = []\n",
    "frequencies = ut.load_unique_frequencies(csv_path)\n",
    "\n",
    "csv_path_geometries = data_dir + \"/KITqm9_geometries.csv\"\n",
    "geometries = ut.load_geometry(csv_path_geometries)\n",
    "\n",
    "csv_spectra = data_dir + \"/DATA_QM9_reduced_2025_03_06.csv\"\n",
    "sprectras = ut.load_spectra(csv_spectra)\n",
    "\n",
    "model_path = \"trained_param/ee_polarizabilities_all_freq_KITqm9_low_fraction_0_006.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "\n",
    "with open(csv_path, newline='', encoding='utf-8') as csvfile:\n",
    "    csv_reader = csv.reader(csvfile, delimiter=',')\n",
    "    \n",
    "    # Read the header to identify column indices\n",
    "    header = next(csv_reader)\n",
    "    frequency_idx = header.index(\"frequency\")\n",
    "    matrix_real_idx = header.index(\"matrix_real\")\n",
    "    matrix_imag_idx = header.index(\"matrix_imag\")\n",
    "    \n",
    "    # Read each row\n",
    "    for row in csv_reader:\n",
    "        try:\n",
    "            idx = int(row[0])\n",
    "        except ValueError:\n",
    "            print(\"Can't read index:\", row[0])\n",
    "            continue\n",
    "\n",
    "        freq_str = row[frequency_idx]\n",
    "        try:\n",
    "            freq_val = float(freq_str)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "        if freq_val not in frequencies:\n",
    "            continue\n",
    "\n",
    "        mol = None\n",
    "        # Now you can look up any 'idx' in constant time\n",
    "        if idx in geometries:\n",
    "            mol = geometries[idx]\n",
    "        else:\n",
    "            continue        \n",
    "        pos = mol.pos\n",
    "        z = mol.z\n",
    "        spectrum_value = ut.get_closest_spectrum_value(sprectras, idx, freq_val)\n",
    "\n",
    "        # Parse JSON for real matrix\n",
    "        matrix_real_str = row[matrix_real_idx]\n",
    "        matrix_imag_str = row[matrix_imag_idx]\n",
    "        try:\n",
    "            real_3x3 = json.loads(matrix_real_str)  # expected shape [3,3]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse real part of matrix for idx:\", idx)\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            imag_3x3 = json.loads(matrix_imag_str)  # expected shape [3,3]\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"Warning: Could not parse imaginary part of matrix for idx:\", idx)\n",
    "            continue\n",
    "\n",
    "        real_mat = torch.tensor(real_3x3, dtype=torch.float32)\n",
    "        imag_mat = torch.tensor(imag_3x3, dtype=torch.float32)\n",
    "        \n",
    "        y = torch.cat([real_mat, imag_mat], dim=-1)  # shape [12]\n",
    "            \n",
    "        data_entry = Data(\n",
    "            idx = mol.idx,\n",
    "            pos=pos.to(torch.float32),    # Atomic positions\n",
    "            z=torch.LongTensor(z),        # Atomic numbers\n",
    "            freq=torch.tensor(float(freq_val), dtype=torch.float32),\n",
    "            spec=torch.tensor(float(spectrum_value), dtype=torch.float32),\n",
    "            y=y,  # Polarizability tensor (target)\n",
    "        )\n",
    "        if spectrum_value > high_spec_cutoff:\n",
    "            dataset.append(data_entry)\n",
    "            count += 1\n",
    "        else:\n",
    "            # Randomly sample ~0.2% of the \"low-spec\" data\n",
    "            if random.random() < low_fraction:\n",
    "                dataset.append(data_entry)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collected 302 high-spec (>0.1) entries.\n",
      "Total dataset length: 1027\n",
      "dataset[0] : 202 tensor(1.5498) tensor(1.4367e-05)\n",
      "dataset[5] : 416 tensor(5.1918) tensor(1.9698e-05)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Collected {count} high-spec (>0.1) entries.\")\n",
    "print(f\"Total dataset length: {len(dataset)}\")\n",
    "\n",
    "ex1 = dataset[0]\n",
    "ex2 = dataset[5]\n",
    "\n",
    "print(\"dataset[0] :\", ex1.idx, ex1.freq, ex1.spec)\n",
    "print(\"dataset[5] :\", ex2.idx, ex2.freq, ex2.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spec mean, std = 0.051924891750768254 0.0951434506295883\n"
     ]
    }
   ],
   "source": [
    "spec_values = [item.spec.item() for item in dataset]\n",
    "spec_mean = np.mean(spec_values)\n",
    "spec_std = np.std(spec_values)\n",
    "\n",
    "print(\"Spec mean, std =\", spec_mean, spec_std)\n",
    "for item in dataset:\n",
    "    old_val = item.spec.item()\n",
    "    norm_val = (old_val - spec_mean) / (spec_std + 1e-8)  # avoid div by zero\n",
    "    item.spec = torch.tensor(norm_val, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real mean, std = 31.399704151449814 165.56148659246568\n",
      "Imag mean, std = 30.816447998693935 226.93200375170045\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "real_vals = []\n",
    "imag_vals = []\n",
    "\n",
    "for item in dataset:\n",
    "    y = item.y  # shape [3,6]\n",
    "    # real => columns [:,:3]\n",
    "    # imag => columns [:,3:]\n",
    "    real_part = y[:, :3].reshape(-1).tolist()   # shape [9]\n",
    "    imag_part = y[:, 3:].reshape(-1).tolist()   # shape [9]\n",
    "    real_vals.extend(real_part)\n",
    "    imag_vals.extend(imag_part)\n",
    "\n",
    "# compute mean, std\n",
    "real_mean, real_std = np.mean(real_vals), np.std(real_vals)\n",
    "imag_mean, imag_std = np.mean(imag_vals), np.std(imag_vals)\n",
    "\n",
    "print(\"Real mean, std =\", real_mean, real_std)\n",
    "print(\"Imag mean, std =\", imag_mean, imag_std)\n",
    "\n",
    "# Now transform each data entry\n",
    "for item in dataset:\n",
    "    y = item.y  # [3,6]\n",
    "    \n",
    "    # real => y[:, :3], shape [3,3]\n",
    "    # imag => y[:, 3:], shape [3,3]\n",
    "    real_slice = y[:, :3]\n",
    "    imag_slice = y[:, 3:]\n",
    "    \n",
    "    # 4) do standard z-score\n",
    "    real_norm = (real_slice - real_mean)/(real_std + 1e-8)\n",
    "    imag_norm = (imag_slice - imag_mean)/(imag_std + 1e-8)\n",
    "    \n",
    "    # reassign\n",
    "    y[:, :3] = real_norm\n",
    "    y[:, 3:] = imag_norm\n",
    "    \n",
    "    item.y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "model = DetaNet(num_features=128,\n",
    "                    act='swish',\n",
    "                    maxl=3,\n",
    "                    num_block=3,\n",
    "                    radial_type='trainable_bessel',\n",
    "                    num_radial=32,\n",
    "                    attention_head=8,\n",
    "                    rc=5.0,\n",
    "                    dropout=0.0,\n",
    "                    use_cutoff=False,\n",
    "                    max_atomic_number=9,\n",
    "                    atom_ref=None,\n",
    "                    scale=1.0,\n",
    "                    scalar_outsize= 4, # 2,#4, \n",
    "                    irreps_out= '2x2e', #'2e',# '2e+2e',\n",
    "                    summation=True,\n",
    "                    norm=False,\n",
    "                    out_type='complex_2_tensor', # '2_tensor',\n",
    "                    grad_type=None,\n",
    "                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DetaNet(\n",
       "  (Embedding): Embedding(\n",
       "    (act): Swish()\n",
       "    (elec_emb): Linear(in_features=16, out_features=128, bias=False)\n",
       "    (nuclare_emb): Embedding(10, 128)\n",
       "    (ls): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (Radial): Radial_Basis(\n",
       "    (radial): Bessel_Function()\n",
       "  )\n",
       "  (blocks): Sequential(\n",
       "    (0): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "        (spec_mlp): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "          (1): Swish()\n",
       "          (2): Linear(in_features=32, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "        (spec_mlp): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "          (1): Swish()\n",
       "          (2): Linear(in_features=32, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): Interaction_Block(\n",
       "      (message): Message(\n",
       "        (Attention): Edge_Attention(\n",
       "          (actq): Swish()\n",
       "          (actk): Swish()\n",
       "          (actv): Swish()\n",
       "          (acta): Swish()\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (lq): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lk): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (lv): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (la): Linear(in_features=256, out_features=256, bias=True)\n",
       "          (lrbf): Linear(in_features=32, out_features=128, bias=False)\n",
       "          (lkrbf): Linear(in_features=128, out_features=128, bias=False)\n",
       "          (lvrbf): Linear(in_features=128, out_features=256, bias=False)\n",
       "        )\n",
       "        (tp): TensorProduct(128x0e x 1x1o+1x2e+1x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "      )\n",
       "      (update): Update(\n",
       "        (actu): Swish()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (outt): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "        (outs): Linear(in_features=128, out_features=128, bias=True)\n",
       "        (uattn): Tensorproduct_Attention(\n",
       "          (lq): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lk): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (lv): Linear(128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 49152 weights)\n",
       "          (ls): Linear(in_features=128, out_features=256, bias=True)\n",
       "          (lvs): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (tp1): TensorProduct(128x1o+128x2e+128x3o x 128x1o+128x2e+128x3o -> 128x0e | 384 paths | 0 weights)\n",
       "          (tp2): TensorProduct(128x0e x 128x1o+128x2e+128x3o -> 128x1o+128x2e+128x3o | 384 paths | 384 weights)\n",
       "          (softmax): Softmax(dim=-1)\n",
       "          (actlvs): Swish()\n",
       "        )\n",
       "        (spec_mlp): Sequential(\n",
       "          (0): Linear(in_features=1, out_features=32, bias=True)\n",
       "          (1): Swish()\n",
       "          (2): Linear(in_features=32, out_features=2, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (tout): Equivariant_Multilayer(\n",
       "    (e_mlp): Sequential(\n",
       "      (0): Linear(128x1o+128x2e+128x3o -> 128x2e | 16384 weights)\n",
       "      (1): Activation [ ] (128x2e -> 128x2e)\n",
       "      (2): Linear(128x2e -> 2x2e | 256 weights)\n",
       "    )\n",
       "  )\n",
       "  (sout): MLP(\n",
       "    (mlp): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): Swish()\n",
       "      (2): Dropout(p=0.0, inplace=False)\n",
       "      (3): Linear(in_features=128, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = torch.load(model_path)\n",
    "model.load_state_dict(state_dict=state_dict)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = dataset[30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5754,  0.3170, -0.0187, -0.1610, -0.5234,  0.6148],\n",
      "        [ 0.3170, -0.6707, -0.1661, -0.5234,  2.0553,  0.5919],\n",
      "        [-0.0187, -0.1661,  0.4377,  0.6148,  0.5919,  2.3250]],\n",
      "       device='cuda:0', grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch_cluster\n",
    "import ase\n",
    "from ase.io import read\n",
    "from ase.visualize import view\n",
    "from ase.build import molecule\n",
    "from code.util.visualize_polarizability import smiles_to_atoms, visualize_polarizability, compare_polarizabilities_eigen\n",
    "\n",
    "result = model(pos=sample.pos.to(device), z=sample.z.to(device), spec=sample.spec.to(device))\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2032, -0.3479, -0.0881,  0.3966, -0.7132,  1.2752],\n",
       "        [-0.3479,  0.8839, -0.0064, -0.7132,  0.5099, -1.6574],\n",
       "        [-0.0881, -0.0064,  0.6884,  1.2752, -1.6574,  3.6398]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg_conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
